%===============================================================================
% Sample bibliopgraphy file for ifaconf.bst style to be used in
% IFAC meeting papers
% Copyright (c) 2007-2008 International Federation of Automatic Control
%===============================================================================

% Used in Introduction section, background on Transformer architecture
@misc{vaswani2017attentionneed,
	title={Attention Is All You Need}, 
	author={Ashish Vaswani and Noam Shazeer and others},
	year={2017},
	eprint={1706.03762},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	note={\url{https://arxiv.org/abs/1706.03762}}, 
}

% Used in Introduction section, parameter to qaulity of output
@misc{touvron2023llamaopenefficientfoundation,
	title={LLaMA: Open and Efficient Foundation Language Models}, 
	author={Hugo Touvron and Thibaut Lavril and others},
	year={2023},
	eprint={2302.13971},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	note={\url{https://arxiv.org/abs/2302.13971}}, 
}


% Used in Introduction section, the required GPUs for foundational models
@misc{bommasani2022opportunitiesrisksfoundationmodels,
	title={On the Opportunities and Risks of Foundation Models}, 
	author={Rishi Bommasani and Drew A. Hudson and others},
	year={2022},
	eprint={2108.07258},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	note={\url{https://arxiv.org/abs/2108.07258}}, 
}

% =========================== Benchmarks ==================================
% HellaSwag
@misc{zellers2019hellaswagmachinereallyfinish,
	title={HellaSwag: Can a Machine Really Finish Your Sentence?}, 
	author={Rowan Zellers and Ari Holtzman and others},
	year={2019},
	eprint={1905.07830},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	note={\url{https://arxiv.org/abs/1905.07830}}, 
}

% WinoGrande
@misc{sakaguchi2019winograndeadversarialwinogradschema,
	title={WinoGrande: An Adversarial Winograd Schema Challenge at Scale}, 
	author={Keisuke Sakaguchi and Ronan Le Bras and others},
	year={2019},
	eprint={1907.10641},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	note={\url{https://arxiv.org/abs/1907.10641}}, 
}

% Arc
@misc{clark2018thinksolvedquestionanswering,
	title={Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge}, 
	author={Peter Clark and Isaac Cowhey and others},
	year={2018},
	eprint={1803.05457},
	archivePrefix={arXiv},
	primaryClass={cs.AI},
	note={\url{https://arxiv.org/abs/1803.05457}}, 
}

% OpenBookQA
@misc{mihaylov2018suitarmorconductelectricity,
	title={Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering}, 
	author={Todor Mihaylov and Peter Clark and others},
	year={2018},
	eprint={1809.02789},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	note={\url{https://arxiv.org/abs/1809.02789}}, 
}
% ======================== Quantizations ==================================
@misc{llamacpp,
	author = {Georgi Gerganov},
	title = {llama.cpp},
	year = {2023},
	publisher = {GitHub},
	journal = {GitHub repository},
	url = {\url{https://github.com/ggerganov/llama.cpp}},
	note = {\url{https://github.com/ggerganov/llama.cpp}}
}

@misc{ggml,
	author = {Georgi Gerganov},
	title = {ggml},
	year = {2022},
	publisher = {GitHub},
	journal = {GitHub repository},
	url = {\url{https://github.com/ggerganov/ggml}},
	note = {\url{https://github.com/ggerganov/ggml}}
}

@misc{lin2024awqactivationawareweightquantization,
	title={AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration}, 
	author={Ji Lin and Jiaming Tang and others},
	year={2024},
	eprint={2306.00978},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	note={\url{https://arxiv.org/abs/2306.00978}}, 
}

@misc{liu2024vptqextremelowbitvector,
	title={VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models}, 
	author={Yifei Liu and Jicheng Wen and others},
	year={2024},
	eprint={2409.17066},
	archivePrefix={arXiv},
	primaryClass={cs.AI},
	note={\url{https://arxiv.org/abs/2409.17066}}, 
}
% =========================================================================

% ============================== Selected LLMs ===========================
@misc{gemmateam2024gemma2improvingopen,
	title={Gemma 2: Improving Open Language Models at a Practical Size}, 
	author={Gemma Team and Morgane Riviere and others},
	year={2024},
	eprint={2408.00118},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	note={\url{https://arxiv.org/abs/2408.00118}}, 
}

@misc{dubey2024llama3herdmodels,
	title={The Llama 3 Herd of Models}, 
	author={Abhimanyu Dubey and Abhinav Jauhri and others},
	year={2024},
	eprint={2407.21783},
	archivePrefix={arXiv},
	primaryClass={cs.AI},
	note={\url{https://arxiv.org/abs/2407.21783}}, 
}

@misc{qwen2.5,
	title = {Qwen2.5: A Party of Foundation Models},
	note = {\url{https://qwenlm.github.io/blog/qwen2.5/}},
	author = {Qwen Team},
	month = {September},
	year = {2024}
}

% =========================================================================

@manual{raspberrypi4,
	title = {Raspberry Pi 4 Model B},
	organization = {Raspberry Pi Ltd},
	year = {2024},
	month = {4},
	note  = {\url{https://datasheets.raspberrypi.com/rpi4/raspberry-pi-4-product-brief.pdf}}
}

@misc{ggmlhuggingface,
	author = {Georgi Gerganov and Xuan Son Nguyen},
	title = {Introduction to ggml},
	year = 2024,
	note = {\url{https://huggingface.co/blog/introduction-to-ggml}}
}

@misc{ggufgithub,
	author = {Georgi Gerganov},
	title = {GGUF},
	year = 2024,
	note = {\url{https://github.com/ggerganov/ggml/blob/master/docs/gguf.md}}
}